% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/coRPysprofiling.R
\name{clean_tokens}
\alias{clean_tokens}
\title{Tokenize words, and remove stopwords from corpus}
\usage{
clean_tokens(corpus, ignore = stopwords::stopwords("en"))
}
\arguments{
\item{corpus}{character vector representing a corpus}

\item{ignore}{stopwords to ignore, optional (default: common English words and punctuations)}
}
\value{
character vector of word tokens
}
\description{
Tokenize words, and remove stopwords from corpus
}
\examples{
coRPysprofiling::clean_tokens("How many species of animals are there in Russia?")
coRPysprofiling::clean_tokens("How many species of animals are there in Russia?", ignore='!"#$\%&\'()*+,-./:;<=>?@[\\\\]^_`{|}~')
}
